# GPU专注AI推理策略说明

## 核心策略

**GPU 100%资源用于AI推理，CPU负责编解码**

## 设计原因

### 1. 显存利用最大化
- 编解码不占用显存
- 更多显存用于AI模型
- 可同时加载多个模型

### 2. 性能优势
- GPU算力100%用于AI
- 避免编解码与AI推理抢资源
- 批处理性能更高

### 3. 成本优势
- CPU解码成本低
- GPU可选配（仅AI需要）
- 横向扩展更灵活

## 架构对比

### 旧方案：GPU编解码 + AI推理
```
24GB显存分配：
- 编解码: 6GB (4K@12路)
- AI推理: 18GB (3个模型)
```

### 新方案：CPU编解码 + GPU纯AI
```
24GB显存分配：
- 编解码: 0GB (CPU处理)
- AI推理: 24GB (可加载更多模型)
```

## 性能指标

### CPU解码
- 1080p: <30% CPU, <20ms延迟
- 支持20路并发

### GPU推理
- YOLOv8n: <15ms@1080p
- 批处理: >200fps (batch=8)
- GPU利用率: >85%

## 降级策略

显存不足时自动降级到CPU推理：

```
显存 < 75%  → GPU全量处理
显存 75-85% → 限制批大小
显存 85-95% → GPU+CPU混合
显存 > 95%  → 纯CPU处理
```

## 适用场景

✅ 推荐场景：
- 多模型AI分析
- 高并发视频流
- 显存资源紧张

❌ 不推荐场景：
- 需要GPU硬件转码
- CPU资源不足
- 无NVIDIA GPU

详见 UpgradePlan.md
